{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2121eaca",
   "metadata": {},
   "source": [
    "## Welcome to the basic neural network tutorial!\n",
    "The following notebook is designed to walk through the process of building and training your first neural network using the standalone MaCh3 python utilities!\n",
    "\n",
    "If you're writing scripts this is encapsulate in the objects in `MaCh3PythonUtils/config_reader` however this guide aims to break apart the process of writing the code for yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a4f83c",
   "metadata": {},
   "source": [
    "The first step is to load in a MaCh3 MCMC fit as input file. This is done using the ChainHandler class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea515328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MaCh3Python Deps\n",
    "from MaCh3PythonUtils.file_handling.chain_handler import ChainHandler\n",
    "from MaCh3PythonUtils.machine_learning.ml_factory import MLFactory\n",
    "\n",
    "# Other imports\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b30cc7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7380ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download file from google drive\n",
    "\n",
    "file_url=\"https://drive.google.com/file/d/1iE6xFhn3BH_HnLUfQ7KFGy2wfeH52Rwf/view?usp=sharing\"\n",
    "\n",
    "# download the file\n",
    "input_file = Path(\"../models/demo_chain.root\")\n",
    "\n",
    "if not input_file.exists():\n",
    "    # download the file\n",
    "    input_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    gdown.download(file_url, str(input_file), quiet=False, fuzzy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in a file, for the purposes of this example we'll use a\n",
    "input_file = Path(\"../../../../T2K/AdaptiveTune/SummerProj/Adapt/NOvA/LongFit/Cut/mcmc_Adapt_NOvA_all_on.root\")\n",
    "\n",
    "# Set up file properties\n",
    "chain_name = 'posteriors'\n",
    "verbose=False\n",
    "\n",
    "chain_handler = ChainHandler(str(input_file), chain_name, verbose=verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d31a84",
   "metadata": {},
   "source": [
    "Okay, now we've loaded in a file we need to do a bit of processing. This means we need to select the variables we care about and apply parameter cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd2f396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly we set things we want to ignore, these are parameters we really don't care about/want to learn!\n",
    "chain_handler.ignore_plots([\"LogL_systematic_xsec_cov\", \"Log\", \"LogL_systematic_osc_cov\"])\n",
    "\n",
    "# Now we add parameters we care about. Note this only need to be a substring of the full name\n",
    "chain_handler.add_additional_plots([\"sin2th\", \"delm2\", \"delta\", \"xsec\"])\n",
    "\n",
    "# The fitting label is special, it's the thing we want to train our network to predict\n",
    "fitting_label = \"LogL\"\n",
    "# We need to make sure the chain handler knows this exists, passing true means it is looking for some with that exact name\n",
    "chain_handler.add_additional_plots(fitting_label, True)\n",
    "\n",
    "# Finally we can do some cuts to get rid of things like burn-in\n",
    "chain_handler.add_new_cuts([\"LogL<30\", \"LogL_systematic_xsec_cov<1234\", \"step>10000\"])\n",
    "\n",
    "# Last step is convert the chain into a pandas dataframe\n",
    "chain_handler.convert_ttree_to_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d259501",
   "metadata": {},
   "source": [
    "Let's quickly use the chain handler to make a plot of the trace and posterior!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b44ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're just grab the first column of our pandas dataframe\n",
    "parameter_vals = chain_handler.ttree_array.iloc[:,0]\n",
    "# Grab the name from column label\n",
    "param_label = chain_handler.ttree_array.columns[0]\n",
    "\n",
    "# Setup figure\n",
    "fig, (trace_ax, post_ax) = plt.subplots(nrows=1, ncols=2)\n",
    "\n",
    "# Plot traces\n",
    "trace_ax.plot(parameter_vals, linewidth=0.5, color='darkorange')\n",
    "\n",
    "# Plot posterior\n",
    "post_ax.hist(parameter_vals, bins=50, color='darkorange', alpha=0.5, orientation='horizontal', density=True)\n",
    "\n",
    "# Merge the two axes\n",
    "plt.setp(post_ax.get_yticklabels(), visible=False)\n",
    "fig.subplots_adjust(wspace=.0)\n",
    "\n",
    "# Set the axis labels\n",
    "trace_ax.set_xlabel(\"Step\")\n",
    "post_ax.set_xlabel(\"Posterior Density\")\n",
    "trace_ax.set_ylabel(param_label)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58068596",
   "metadata": {},
   "source": [
    "## Machine learning\n",
    "Okay now we've done some very basic file manipulation, it's time for some machine learning!\n",
    "All algorithms use the same common `MLFactory` interface so let's go about configuring it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b769e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step we need to initialise the factory\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "model_output=Path(\"../models/my_model\")\n",
    "# Make sure the model output directory exists\n",
    "model_output.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# The factory produces ML models, we need to pass it the chain handler and the fitting label to get started\n",
    "ml_factory = MLFactory(chain_handler, fitting_label, f\"{model_output}.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47842a01",
   "metadata": {},
   "source": [
    "Now we need to define a model, for this demonstration we'll make a very simple neural network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0bc7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â Finally we need to set the layers\n",
    "\n",
    "# In the YAML format this would be simple but here we'll use some helper functions\n",
    "def dense_layer(n_neurons: int, activation: str, regularize: bool = True):\n",
    "    '''This function sets the properties of a dense layer'''\n",
    "    return {'dense': {\n",
    "        'units': n_neurons,\n",
    "        'activation': activation,\n",
    "        'kernel_regularizer': regularize\n",
    "    }}\n",
    "    \n",
    "def batch_norm(momentum: float = 0.9):\n",
    "    '''This function sets the properties of a batch norm layer'''\n",
    "    return {'batchnorm': {\n",
    "        'momentum': momentum\n",
    "    }}\n",
    "    \n",
    "def dropout_layer(dropout_rate: float):\n",
    "    '''This function sets the properties of a dropout layer'''\n",
    "    return {'dropout': {\n",
    "        'rate': dropout_rate\n",
    "    }}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "\n",
    "# Setup layers\n",
    "layers.append(batch_norm(0.9))\n",
    "layers.append(dense_layer(64, 'relu'))\n",
    "layers.append(dense_layer(64, 'relu'))\n",
    "layers.append(batch_norm(0.9))\n",
    "layers.append(dense_layer(64, 'relu'))\n",
    "layers.append(batch_norm(0.9))\n",
    "layers.append(dense_layer(32, 'relu'))\n",
    "layers.append(dense_layer(8, 'relu'))\n",
    "layers.append(dense_layer(1, 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a10c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now want the actual neural network properties\n",
    "# Usually you set this using a YAML file (see configs for some examples) but we'll do this manually for now\n",
    "build_settings = {\n",
    "    # Loss function\n",
    "    'loss': 'mse',\n",
    "    # Metrics to measure\n",
    "    'metrics': ['mae', 'mse'],\n",
    "    # Learning rate\n",
    "    'learning_rate': 0.001,\n",
    "}\n",
    "\n",
    "# Settings used when the model is fitting\n",
    "fit_settings = {\n",
    "    'batch_size': 4096,\n",
    "    'epochs': 100,\n",
    "    'validation_split': 0.2,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa21f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can make the model\n",
    "ml_model = ml_factory.make_interface('TensorFlow', 'sequential', Layers=layers, FitSettings=fit_settings, BuildSettings=build_settings)\n",
    "\n",
    "# Let's use 20% of the data for testing\n",
    "ml_model.set_training_test_set(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c8e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to train our network\n",
    "ml_model.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ecf564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to test\n",
    "ml_model.test_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbaf177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can save it\n",
    "ml_model.save_model(f\"{model_output}.keras\")\n",
    "\n",
    "\n",
    "# We need to save the scaling information\n",
    "ml_model.save_scaler(str(model_output.parent.joinpath(Path(\"my_scaler.pkl\"))))\n",
    "print(\"Model saved to: \", model_output)\n",
    "print(\"Scaler saved to: \", model_output.parent.joinpath(Path(\"my_scaler.pkl\")))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
